{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb401df7-fa68-4d97-b195-b5b84e592629",
   "metadata": {},
   "source": [
    "# open_dataset() data via:\n",
    "1) add_dataset_path(url without filename) -> open_dataset(filename without zarr ext)\n",
    "2) _open_dataset(url with filename.zarr)\n",
    "\n",
    "#### Findings:\n",
    "\n",
    "1) When trying to __open zarr stored in GS via declaring GS URL & HTTPS URL__\n",
    "   \n",
    "- JSON decoding error:\n",
    "\n",
    "File ~/anemoi/gh_most_uptodate/troubleshooting/anemoi-datasets/src/anemoi/datasets/data/stores.py:171, in open_zarr(path, dont_fail, cache)\n",
    "    168         store = zarr.LRUStoreCache(store, max_size=cache)\n",
    "    169         print(\"44\")\n",
    "--> 171     __return zarr.convenience.open(store, \"r\")__\n",
    "    172 except zarr.errors.PathNotFoundError:\n",
    "    173     if not dont_fail:\n",
    "\n",
    "- Missing 'data' feature variable within the Zarr store\n",
    "   - *To get around error, create a 'data' variable within the Zarr store\n",
    "     \n",
    "2) When trying to __open zarr stored in S3 via declaring S3 URL__\n",
    "   \n",
    "- JSON decoding error:\n",
    "\n",
    "File ~/anemoi/gh_most_uptodate/troubleshooting/anemoi-datasets/src/anemoi/datasets/data/stores.py:171, in open_zarr(path, dont_fail, cache)\n",
    "    168         store = zarr.LRUStoreCache(store, max_size=cache)\n",
    "    169         print(\"44\")\n",
    "--> 171     __return zarr.convenience.open(store, \"r\")__\n",
    "    172 except zarr.errors.PathNotFoundError:\n",
    "    173     if not dont_fail:\n",
    "\n",
    "- Missing 'data' feature variable within the Zarr store\n",
    "   - To get around error, create a 'data' variable within the Zarr store\n",
    "     \n",
    "3) When trying to __open zarr stored in S3 via declaring HTTPS URL__\n",
    "\n",
    "- An output from open_dataset() gets generated after *, BUT error getting:\n",
    "   - metadata from zarr, as attributes are empty\n",
    "   - dates from zarr and thus, frequency from zarr\n",
    "   - statistics from zarr\n",
    "   - resolution from zarr\n",
    "   - name_to_index from zarr and thus, variables from zarr\n",
    "     \n",
    "- Missing 'data' feature variable within the Zarr store\n",
    "   - *To get around error, create a 'data' variable within the Zarr store \n",
    "\n",
    "4) When trying to __open zarr stored on local disk__\n",
    "\n",
    "- An output from open_dataset() gets generated after *, BUT error getting:\n",
    "   - metadata from zarr, as attributes are empty\n",
    "   - dates from zarr and thus, frequency from zarr\n",
    "   - statistics from zarr\n",
    "   - resolution from zarr\n",
    "   - name_to_index from zarr and thus, variables from zarr\n",
    "     \n",
    "- Missing 'data' feature variable within the Zarr store\n",
    "   - *To get around error, create a 'data' variable within the Zarr store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ae2f0-aaf0-4772-926f-7f7c6b766fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZARR in GS\n",
    "from __init__ import add_dataset_path\n",
    "from __init__ import open_dataset\n",
    "\n",
    "add_dataset_path(\"https://console.cloud.google.com/storage/browser/gcp-public-data-arco-era5/ar/\")\n",
    "#add_dataset_path(\"gs://gcp-public-data-arco-era5/ar/\")\n",
    "\n",
    "# Opening entire dataset w/out filter.\n",
    "ds = open_dataset(\"1959-2022-1h-360x181_equiangular_with_poles_conservative\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc1b9ba-7116-4b10-ab68-9221024d890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZARR in S3\n",
    "from __init__ import add_dataset_path\n",
    "from __init__ import open_dataset, list_dataset_names\n",
    "\n",
    "add_dataset_path(\"https://noaa-ufs-gdas-pds.s3.amazonaws.com/\")#\n",
    "#add_dataset_path(\"s3://noaa-ufs-gdas-pds/\")\n",
    "\n",
    "# Opening entire dataset w/out filter.\n",
    "ds = open_dataset(\"test_ar\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20887e73-d79b-476a-b135-d2c275047559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZARR in ECMWF Site\n",
    "from __init__ import add_dataset_path\n",
    "from __init__ import open_dataset\n",
    "\n",
    "add_dataset_path(\"https://object-store.os-api.cci1.ecmwf.int/ml-examples/\")\n",
    "\n",
    "# Opening entire dataset w/out filter.\n",
    "ds = open_dataset(\"an-oper-2023-2023-2p5-6h-v1\")\n",
    "\n",
    "# Subsetting is the action of filtering the dataset by it’s first dimension (dates).\n",
    "'''\n",
    "** start & end: **\n",
    "The following are equivalent ways of describing start or end:\n",
    "\n",
    "2020 and \"2020\"\n",
    "202306, \"202306\" and \"2023-06\"\n",
    "20200301, \"20200301\" and \"2020-03-01\"\n",
    "\n",
    "Note: \n",
    "- start=\"2020\" is equivalent to start=\"2020-01-01\" while end=\"2020\" is equivalent to end=\"2020-12-31\".\n",
    "- Frequency of the dataset will change how the end option is interpreted: - end=\"2020\" with a frequency of one hour \n",
    "is equivalent to end=\"2020-12-31 23:00:00\" - end=\"2020\" with a frequency of 6 hours is equivalent to end=\"2020-12-31 18:00:00\"\n",
    "\n",
    "** frequency **\n",
    "- The new frequency must be a multiple of the original frequency.\n",
    "- To artificially increase the frequency, you can use the \"interpolate_frequency\" option, which will create new dates in the \n",
    "dataset by linearly interpolating the data values between the original dates. Ex: ds = open_dataset(dataset, interpolate_frequency=\"10m\")\n",
    "\n",
    "'''\n",
    "#ds = open_dataset(\"an-oper-2023-2023-2p5-6h-v1\", start=\"2023-1-01\", end=\"2023-12-30\")# ECMWF ERA5 data file's metadata reveals dates are from 2023-1-01T00:00:00 to 2023-12-31T18:00:00 found via ds.dates\n",
    "#ds = open_dataset(\"an-oper-2023-2023-2p5-6h-v1\", start=\"2023\", end=\"2023\")# ECMWF ERA5 data file's metadata reveals dates are from 2023-1-01T00:00:00 to 2023-12-31T18:00:00\n",
    "#ds = open_dataset(\"an-oper-2023-2023-2p5-6h-v1\", frequency = \"6h\", start=\"2023\", end=\"2023\")# ECMWF ERA5 data file's metadata reveals dates are from 2023-1-01T00:00:00 to 2023-12-31T18:00:00 @ freq. multiples of 6h, 12h, etc; must be of proper frequency or will rcv error\n",
    "#ds = open_dataset(\"an-oper-2023-2023-2p5-6h-v1\", interpolate_frequency=\"1h\", start=\"2023\", end=\"2023\")\n",
    "#ds = open_dataset(\"an-oper-2023-2023-2p5-6h-v1\", \"an-oper-2023-2023-2p5-6h-v1\")#, thinning=2)\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a2d95-126b-4777-bbcb-8646f7e8a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZARR in Local\n",
    "from __init__ import add_dataset_path\n",
    "from __init__ import open_dataset, list_dataset_names\n",
    "import os \n",
    "\n",
    "add_dataset_path(os.getcwd())\n",
    "\n",
    "# Opening entire dataset w/out filter.\n",
    "ds = open_dataset(\"gcp_ar_era5_subset\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8676b1-0cc7-4890-afb8-8e2a23e736e1",
   "metadata": {},
   "source": [
    "# Read output info of open_dataset(ZARR_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f41d3-a054-4b1c-ae95-6c5ca49b86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Methods of open_dataset's output:\n",
    "\n",
    "# The following methods and attributes are available for the objects returned by open_dataset.\n",
    "\n",
    "# Return the dataset’s metadata.\n",
    "ds.metadata()\n",
    "\n",
    "# Return the dataset’s provenance information.\n",
    "#ds.provenance\n",
    "\n",
    "# For debugging. Given the index of a variable, this will return from which Zarr store it will be loaded. This is useful to debug combining datasets with join.\n",
    "#ds.source\n",
    "\n",
    "# For debugging. Return the dataset’s internal tree structure.\n",
    "#ds.tree()\n",
    "\n",
    "# Demo: Attributes of open_dataset's output:\n",
    "# '''\n",
    "# When building a dataset, Ref: https://anemoi-datasets.readthedocs.io/en/latest/building/introduction.html\n",
    "# '''\n",
    "\n",
    "# shape: A tuple of the dataset’s dimensions.\n",
    "#ds.shape\n",
    "\n",
    "# field_shape: The original shape of a single field, either 1D or 2D. When building datasets, the fields are flattened to 1D.\n",
    "#ds.field_shape\n",
    "\n",
    "# dtype: The dataset’s NumPy data type.\n",
    "#ds.dtype\n",
    "\n",
    "# dates: The dataset’s dates, as a NumPy vector of datetime64 objects.\n",
    "#ds.dates\n",
    "\n",
    "# frequency: The dataset’s frequency (i.e the delta between two consecutive dates) in hours.\n",
    "#ds.frequency\n",
    "\n",
    "# latitudes: The dataset’s latitudes as a NumPy vector.\n",
    "#ds.latitudes\n",
    "\n",
    "# longitudes: The dataset’s longitudes as a NumPy vector.\n",
    "#ds.longitudes\n",
    "\n",
    "# statistics: The dataset’s statistics. This is a dictionary with the following entries:\n",
    "# ds.statistics\n",
    "\n",
    "# Example: Statistics can be used such that each entry is a NumPy vector with the same length as the number of variables, each element corresponding to a variable. You can therefore use it like:\n",
    "#values = ds[0]\n",
    "#normalized = (values - ds.statistics[\"mean\"])/ ds.statistics[\"stdev\"]\n",
    "\n",
    "\n",
    "# resolution: The dataset’s resolution.\n",
    "#ds.resolution\n",
    "\n",
    "# name_to_index: A dictionary mapping variable names to their indices.\n",
    "#ds.name_to_index[\"2t\"]\n",
    "\n",
    "# variables: A list of the dataset’s variable names, in the order they appear in the dataset.\n",
    "#ds.variables\n",
    "\n",
    "# missing: The set of indices of the missing dates.\n",
    "#ds.missing\n",
    "\n",
    "# grids: A tuple of number of grid points for each dataset that is combined with the grids method.\n",
    "#ds.grids\n",
    "\n",
    "# Demo: Slicing & Indexing a dataset opened via open_dataset:\n",
    "#ds[0]\n",
    "#ds[-1]\n",
    "#ds[0:10]\n",
    "#ds[0:10:2]\n",
    "#ds[0, 1, :]\n",
    "\n",
    "# *** 10/10/24 ====> LEFT OFF ON GUIDE: https://anemoi-datasets.readthedocs.io/en/latest/using/combining.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd8d3f-404b-4c7d-b873-ac9f89d3c548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e25b2336-649c-408c-b122-496b98300943",
   "metadata": {},
   "source": [
    "# Create subset ERA5 AR Zarr in GS & Save to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ab33f-d7e8-4ea8-ad12-c28873171639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import gcsfs\n",
    "\n",
    "## Load Zarr via open_zarr(direct gs url)\n",
    "# Does not extract attibutes UNLESS you declare the variable and then, test[VARIBALE_NAME].attrs\n",
    "gcp_ar_era5_subset = xr.open_zarr('gs://gcp-public-data-arco-era5/ar/1959-2022-1h-360x181_equiangular_with_poles_conservative.zarr', \n",
    "                    chunks={'time': 48},\n",
    "                    consolidated=True)\n",
    "gcp_ar_era5_subset = gcp_ar_era5_subset.isel(time=slice(-15, -1))\n",
    "gcp_ar_era5_subset \n",
    "\n",
    "\n",
    "## Load Zarr via open_zarr(fs.get_mapper(direct gs url))\n",
    "# bucket_name = \"gcp-public-data-arco-era5\"\n",
    "# fs = gcsfs.GCSFileSystem(project=f'{bucket_name}_fs')\n",
    "\n",
    "# print(f\"Data Categories (higher-level prefix):\\n{fs.ls(bucket_name)}\")\n",
    "# mapper = fs.get_mapper(f\"gs://{bucket_name}/ar/1959-2022-1h-360x181_equiangular_with_poles_conservative.zarr\")\n",
    "\n",
    "# ds = xr.open_zarr(mapper)\n",
    "# gcp_ar_era5_subset = ds.isel(time=slice(-10, -5))\n",
    "# gcp_ar_era5_subset\n",
    "\n",
    "# Save to local disk\n",
    "#gcp_ar_era5_subset.to_zarr('gcp_ar_era5_subset.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237997c1-67ac-4ea9-be58-ce7472c770b1",
   "metadata": {},
   "source": [
    "# Verify generated anemoi formatted Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505670d6-f52b-414b-935b-0dc0728192b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xarray as xr\n",
    "# import gcsfs\n",
    "\n",
    "# ## Load Zarr\n",
    "# vars = ['2m_temperature',\n",
    "#         '10m_u_component_of_wind',\n",
    "#         'geopotential',\n",
    "#         '10m_v_component_of_wind',\n",
    "#         'surface_pressure']\n",
    "# gcp_ar_era5_subset = xr.open_zarr(\"test_s3_zarr.zarr\")\n",
    "# gcp_ar_era5_subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851d65d-53cf-49ee-ad06-19f05fc18bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anemoi",
   "language": "python",
   "name": "anemoi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
